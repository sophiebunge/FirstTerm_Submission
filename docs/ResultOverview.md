# Orientationproject Result Submission

_Submission 15.03.25_

## 1. Result Presentation:

---

Access the Project: [Visit website](https://avatarreact-2.onrender.com/)

---

---

A guide how to install and run locally can be found in the NavMenu **"How to Run it"** and the code can be found in the same submission github folder.

---

### Title

Digital Twin

### Description

This website recognizes a person's emotion through a webcam using the DeepFace library and displays the detected emotion. The recognized emotion is then sent to an avatar from _ReadyPlayerMe.com_, which mimics the emotion. In the center of the website is a small experiment where users can try to identify the emotion showcased in the pictures by mimicking it (though it currently doesn't provide feedback on whether they are right or wrong). The avatars are fully customizable, and for user experiments, I plan to run the project locally, allowing easy integration of customized avatars.

### Results

---

Screenshots of the Results can be found [here.](https://owncloud.gwdg.de/index.php/s/EVKGwD5JIsfVSXw)

---

An avatar that mimics the captured emotions, which is the MVP I wanted to reach based on my first project plan.

### Discussion of Results

The results are the MVP I was aiming for, and the fact that it works is still a pleasant surprise to me.

### Next steps, future work

The goal would be to design a well-structured experiment that can be tested by users to determine if they are influenced by the avatar's reactions.

## 2. Project Documentation:

---

Download the project diary here: [Download](https://owncloud.gwdg.de/index.php/s/YgKN2rIEq0pw5Su) <br> _at the end I did managed to deploy the website otherwise written in the diary._

---

### Reflections

**Technical Reflections:**
I initially wrote that I wanted to create my project on TouchDesigner to take this oportunity to lear the program, however, TouchDesigner resulted to not work for me. I had issues on creating a workflow to adapt an emotion recognition inside the app. This took my quite some time to figure out, that this won't be the way to go. Nevertheless, I find on creating a React App a good enough learning anyways, and personally satisfactory to gain more knowledge in this.

**MVP and Best-Case Scenario Reflections:**
I’ve reached the MVP, but the best-case scenario is still quite a way off. What’s left to do is design a solid experiment scenario to test, as well as develop an effective method for analyzing the outcomes.

**What would I do differently?**
Although the results are okay-ish in my opinion, I had hoped for better final outcomes with a thorough analysis based on a well-designed experiment. What I hadn’t fully considered, though, is that much of what I’m doing is also a learning process. This isn’t a typical project where I’ve worked with the same programs and skills multiple times; it involves many “firsts” for me. Nonetheless, this is exactly why I embarked on this study—to learn as much as possible. However, next time I will aim to plan way more time to not overwork myself. I would like to focus more in one thing, and try to master that, instead of having a little knowledge everywhere but nothing rock solid.

**Challenge of your comfort zone?**
Pretty much everything, to be honest. This is only my second time creating a React app, but almost everything else is new to me. I’ve learned how to handle both frontend and backend, create and work with virtual environments, use ML libraries like DeepFace, integrate avatars into a React app, and apply MorphTargets to modify their facial expressions.

**Reflection of original workplan**
I didn’t follow the initial work plan due to time constraints. The final semester submissions took up a significant amount of time, and I wasn’t able to dedicate the planned hours to this project each week. This is likely because this semester introduced a lot of new material and knowledge that I had never encountered before.
